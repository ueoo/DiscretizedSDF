import argparse
import glob
import json
import math
import os
import pickle
import shutil

import numpy as np
import torch

from skimage.io import imread, imsave

from utils.graphics_utils import normal_from_depth_image


"""
    Convert NeRO Blender dataset into NeRF format.
"""


def read_pickle(pkl_path):
    with open(pkl_path, "rb") as f:
        return pickle.load(f)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--path", type=str, default="data/glossy_relight/relight_gt", help="path to the GlossyBlender dataset"
    )

    opt = parser.parse_args()
    scenes = os.listdir(opt.path)
    for scene in scenes:
        root = os.path.join(opt.path, scene)
        output_path = os.path.join(opt.path + "_blender", scene)
        if not os.path.exists(output_path):
            os.makedirs(output_path, exist_ok=True)

        print(f"[INFO] Data from {root}")
        img_num = len(glob.glob(f"{root}/*.pkl"))
        img_ids = [str(k) for k in range(img_num)]
        cams = [read_pickle(f"{root}/{k}-camera.pkl") for k in range(img_num)]  # pose(3,4)  K(3,3)
        img_files = [f"{root}/{k}.png" for k in range(img_num)]
        depth_files = [f"{root}/{k}-depth0001.exr" for k in range(img_num)]

        frames = []
        os.makedirs(f"{output_path}/depth", exist_ok=True)
        for image, cam, depth in zip(img_files, cams, depth_files):
            img_id = int(os.path.basename(image)[:-4])
            w2c = np.array(cam[0].tolist() + [[0, 0, 0, 1]])
            c2w = np.linalg.inv(w2c)
            c2w[:3, 1:3] *= -1  # opencv -> blender/opengl
            frames.append(
                {
                    "file_path": os.path.join("rgb", os.path.basename(image)).replace(".png", ""),
                    "transform_matrix": c2w.tolist(),
                }
            )
            depth = imread(depth)[:, :, 0]
            depth = depth.astype(np.float32) / 65535 * 15
            mask = depth < 14.5
            normal = normal_from_depth_image(
                torch.from_numpy(depth).float(), torch.from_numpy(cams[0][1]).float(), torch.from_numpy(c2w).float()
            )
            normal = torch.nn.functional.normalize(normal, dim=-1).numpy() * mask[:, :, None]
            normal = (normal + 1) / 2
            normal = (normal * 255).astype("uint8")
            imsave(f"{output_path}/depth/{img_id}_normal.png", normal)

        mask = (mask[..., None] * 255).astype(np.uint8)
        fl_x = float(cams[0][1][0, 0])
        fl_y = float(cams[0][1][1, 1])

        transforms = {
            "w": 800,
            "h": 800,
            "fl_x": fl_x,
            "fl_y": fl_y,
            "cx": 400,
            "cy": 400,
            # 'aabb_scale': 2,
            "frames": frames,
        }

        # write json
        json_out_path = os.path.join(output_path, f"transforms_train.json")
        print(f"[INFO] write to {json_out_path}")
        with open(json_out_path, "w") as f:
            json.dump(transforms, f, indent=2)
        json_out_path = os.path.join(output_path, f"transforms_test.json")
        with open(json_out_path, "w") as f:
            json.dump(transforms, f, indent=2)

        # write imgs
        img_out_path = os.path.join(output_path, "rgb")
        if not os.path.exists(img_out_path):
            os.makedirs(img_out_path, exist_ok=True)
        print(f"[INFO] Process rgbs")
        print(f"[INFO] write to {img_out_path}")
        for img_id in img_ids:
            depth = imread(f"{root}/{img_id}-depth0001.exr")[:, :, 0]
            depth = depth.astype(np.float32) / 65535 * 15
            mask = depth < 14.5
            mask = (mask[..., None] * 255).astype(np.uint8)

            image = imread(f"{root}/{img_id}.png")[..., :3]
            image = np.concatenate([image, mask], axis=-1)

            imsave(f"{img_out_path}/{img_id}.png", image)

        print(f"[INFO] Scece [{scene}] Finished.")
